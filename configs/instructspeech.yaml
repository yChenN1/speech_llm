---
sample_rate: 16000
clip_duration: 10.
max_caption_len: 100

train_datasets:
    LJSpeech:
        root: "/mnt/fast/nobackup/scratch4weeks/yc01815/Speech_gen_dataset/gen_speech_v1/train_instruct.csv"
        split: "train"

test_datasets:
    LJSpeech:
        root: "/mnt/fast/nobackup/scratch4weeks/yc01815/Speech_gen_dataset/gen_speech_v1/valid_instruct.csv"
        split: "test"
        
audio_encoder:
    name: XCodec2
    n_quantizers: 1

tokenizer:
    name: BertXCodec2ATA

model:
    name: Llama
    block_size: 2048  # Maximize block size
    vocab_size:  # Leave blank. Parsed later from len(tokenier)
    n_layer: 12
    n_head: 12
    n_embd: 768
    
train:
    device: "cuda"
    num_workers: 16
    loss: ce_loss
    optimizer: AdamW
    lr: 1e-4
    warm_up_steps: 1000  # Leave blank if no warm up is used
    batch_size_per_device: 4
    test_every_n_steps: 2000
    save_every_n_steps: 20000
    training_steps: 200000
    resume_ckpt_path:  # Leave blank if train from scratch